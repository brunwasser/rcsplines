---
title: "Using Restricted Cubic Splines in Structural Equation Models"
author: "Steven M. Brunwasser, Ph.D."
date: "`r Sys.Date()`"
output:
  html_document:
    theme: sandstone
    highlight: tango
    toc: true
    toc_depth: 3
    toc_float: true
    code_folding: hide
---

```{r}
knitr::opts_chunk$set(echo = TRUE,
                      warning = F,
                      message = F 
                      )
```


## Overview
The purpose of this page is to demonstrate how restricted cubic splines (RCSs) to model nonlinear effects of predictors and nonlinear growth trajectories within a structural equation models (SEMs). First, I will show how to implement RCSs in ordinary least squares (OLS) and generalized least square (GLS) models. Then I will show how to implement RCSs in the context of SEMs.

## Workspace Prep
Load require package. You may have to install these packages if you have never installed them before using the **install.packages()** function. 
```{r}
require( data.table )
require( ggplot2 )
require( mgcv )
require( rms )
require( Hmisc )
require( lavaan )
require( ERP )
```


## Demonstration in OLS regression
Prior to demonstrating the use of restricted cubic splines (RCSs) in structural equation models (SEM), we will use RCSs to model a nonlinear association in an ordinary least squares (OLS) model using the [rms](https://CRAN.R-project.org/package=rms) package. There are several helpful overviews for this package, including [this one](https://www.nicholas-ollberding.com/post/an-introduction-to-the-harrell-verse-predictive-modeling-using-the-hmisc-and-rms-packages/) and [this one](https://www.r-bloggers.com/2016/07/introduction-to-the-rms-package/).  

First, let's simulate data with a nonlinear association that does not follow a simple polynomial function. Goldfield and Wujciak-Jens provide [helpful code](https://www.rdatagen.net/post/2022-08-09-simulating-data-from-a-non-linear-function-by-specifying-some-points-on-the-curve/) to accomplish this. Please see their code and explanations for a detailed explanation of this approach.

As seen in the figure below, we simulated a response variable ($y$) whose values twice rise and fall rapidly as values of the predictor variable ($x$) increase. The predictor and response variables are housed in the dataframe *mdata*.
```{r}
x <- c(20, 30, 40, 50, 60, 70, 80)
y <- c(15, 40, 25, 22, 35, 24, 15)

dd <- data.table(x = x, y = y)

dc <- copy(dd)

dc[, xend := (shift(x, type = "lead"))]
dc[, yend := (shift(y, type = "lead"))]
dc <- dc[ -.N]
dc[, id := .I]

interp_line <- function(x, y, xend, yend) {
  slope <- (yend - y)/(xend - x)
  b <- y - slope*x
  newx <- seq(x, xend, length = 100)
  newy <- newx*slope + b
  
  data.table::data.table(x = newx, y = newy)
}

dx <- dc[, interp_line(x, y, xend, yend), keyby = id]
dx

gam.fit <- gam(y ~ s(x, k = 7), data = dx)


dx[, ypred := predict(gam.fit)]


set.seed(123)
mdata <- data.table(x = runif(10000, 20, 85))
mdata$y <- predict(gam.fit, newdata = mdata) + rnorm(nrow(mdata),0, 2)

ggplot(data = mdata, aes(x = x, y = y)) +
  geom_point(size = 1)  +
  scale_x_continuous( breaks = seq( 20, 80, 5 ) )

```

We start by storing key features of our data frame using the **datadist()** function in the *rms* package. This will make data summaries, predictions, and plotting more efficient. We then use the **ols()** function to run a regression model (stored in an object called *ols.rcs5*) in which the effect of $x$ on $y$ is modeled with a 6-knot RCS. RCSs require $df=k-1$, where $k$ is the number of knots. Therefore, the effect of $x$ will require  ($df=5$). Note, that the model code looks like a standard R regression model (y ~ x) except that the function **rcs()** is called for the $x$ variable, telling the regression model to estimate a restricted cubic spline with 6 knots. We did not specify where to place the knots, so *rms* will use the default position values with the outer knots placed at the 0.10 and 0.90 quantiles and inner knots at equally spaced intervals in between.  
```{r}

dd <- datadist( mdata )
options( datadist = 'dd' ) 

ols.rcs5 <- ols( y ~ rcs( x, 6 ), data = mdata )
```


The **print()** function shows indices of model fit (e.g., $R^2$), the model likelihood ratio test, and the $k-1$ effects of $x$, representing the model-implied rate of change in $y$ for the different segments of $x$ defined by the spline knots. We can see that the effects of $x$ is easily different than 0 with alternating signs, capturing the rapid rises and descents of $y$ over the range of $x$ values.    
```{r}
print( ols.rcs5 )
```

We typically would like a statistical test for the overall effect of $x$ with $df=5$ in this case. The **anova.rms()** function provides an overall $F$ test and a test of whether there is evidence of nonlinearity in the effect of $x$ on $y$.
```{r}
anova( ols.rcs5 )
```

Interpreting the 5 RCS coefficient for the effect of $x$ on $y$ is not straightforward. The best way to interpret the effect is visually. The **Predict()** function makes it simple to obtain model-predicted values of $y$ against levels of $x$. We can plot these predictions easily using **ggplot2**. 
```{r}
ggplot( Predict( ols.rcs5, x ) )
```

A commonly used alternative to RCSs for modeling nonlinear effects of continuous predictors are polynomial regressions, where we include values of $x$ raised to higher powers (e.g., $x^2$ for a quadratic effect). Let's run a competing polynomial regression model that invests the same number of $df$ as the RCS model we ran previously. We can use the **pol()** function to run a quintic polynomial regression with $df=5$.    
```{r}
ols.pol5 <- ols( y ~ pol( x, 5 ), data = mdata )
```

Now we can compare indices of model fit across the RCS and polynomial models. We can see that the $R^2$ value is slightly larger in the RCS model compared to the quintic polynomial (0.89 vs. 0.84), though both do quite well in fitting the data.
```{r}
ols.model <- c('6-Knot RCS','Quintic Polynomial')
ols.r2 <- c( ols.rcs5$stats[4], ols.pol5$stats[4] )
ols.fit <- data.frame( rbind( ols.model, ols.r2 )  )
ols.fit
```


We can better see how well the RCS and quintic polynomial models do in capturing the data by plotting the model predictions against the observed data. In the plot below, the vertical dashed lines show where the 5 RCS knots are located. Both do a good job fitting the data, but the RCS model better captures the drop and rise in $y$ than the polynomial model. Also, the polynomial model prediction line curves up after the final knot on the far right end of the $x$ distribution, whereas the RCS model constrains the line to be linear (straight) in the extremes of the distribution, beyond the first and last knots. 
```{r}
ols.rcs5.pred <- Predict( ols.rcs5, x ) 
ols.pol5.pred <- Predict( ols.pol5, x ) 

ols5.pred <- rbind( ols.rcs5.pred, ols.pol5.pred )
ols5.pred$model <- rep( c( '6-Knot RC Spline','Quintic Polynomial' ), each = 200 )

cbbPalette <- c("#E69F00","#0072B2" , "#56B4E9", "#009E73", "#F0E442", "#D55E00", "#CC79A7")

ols.pred5.plot <- ggplot( ) +
  geom_point( data=mdata, aes( x=x, y=y ), color = 'darkgray', shape = 1 ) +
  geom_line( data=ols5.pred, aes( x=x, y=yhat, group = model, colour=model, linetype = model ), size = 2 ) +
  scale_color_manual( values=cbbPalette ) +
  geom_vline( xintercept = rcspline.eval( mdata$x, nk = 6, knots.only = T ), linetype = 3 ) +
  scale_x_continuous( breaks = rcspline.eval( mdata$x, nk = 6, knots.only = T ),
                      labels = c('23.15\nKnot 1','35.06\nKnot 2','46.74\nKnot 3','58.04\nKnot4','69.63\nKnot5','81.61\nKnot 6')) +
  labs( colour='Model Type',
        linetype ='Model Type') +
  theme( axis.text.x =  element_text( size = 12, face = 'bold'),
         legend.title = element_text( size = 14, face = 'bold'),
         legend.text = element_text( size = 12 ),
         axis.title = element_text( size = 14, face = 'bold'),
         legend.position = 'bottom' )
ols.pred5.plot

```
<br>

## GLS Model with ERP Data

In this section, we'll use data from the [ERP package](https://cran.r-project.org/web/packages/ERP/vignettes/ERP.html) to model event-related potential (ERP) trajectories. I use these data because ERP amplitudes follow complex nonlinear trajectories. The impulsivity data from the ERP package is in the wide format with repeated measures of amplitude stored in multiple columns. Below, we reshape the data so that it is in the long format. 
```{r}
data(impulsivity)

impulsivity1 <- subset( impulsivity, !duplicated( impulsivity$Subject ) )

imp <- reshape( impulsivity1,
                direction = 'long',
                timevar = 'time',
                varying = list( out = colnames( impulsivity )[5:505] ),
                idvar = 'Subject',
                times = seq( 0, 1000, 2 )
                )

```


Now that the data is in the appropriate format, we can model longitudinal trajectories using RCSs. As these are repeated measures data, we'll use GLS models with a first-order autoregressive error structure (AR1) to capture non-independence in the errors over time. As we don't know how many knots are needed for the RCSs to obtain a reasonable fir, below I fit GLS models modeling the effect of time with 8-, 7-, and 6-knot RCSs. We can compare the Akaike Information Criterion for each of these models to aid in model selection [(Harrell 2015)](https://www.amazon.com/Regression-Modeling-Strategies-Applications-Statistics/dp/3319194240). The model with the smallest AIC value will be considered the one that best captures the effect of x on y without overfitting. The 7-knot RCS model ($df=6$ invested in the time effect) is best according to the AIC. 
```{r}
ddimp <- datadist( imp )
options( datadist = ddimp )



# imp.rcs7 <- Gls( T_0 ~ rcs( time, 8 ),
#                  correlation = corAR1( form = ~time | Subject  ),
#                  data = imp,
#                  x = T ) 
# save( imp.rcs7, file='imp.rcs7.RData' )
load( 'imp.rcs7.RData' )

# imp.rcs6 <- Gls( T_0 ~ rcs( time, 7 ),
#                  correlation = corAR1( form = ~time | Subject  ),
#                  data = imp,
#                  x = T )
# save( imp.rcs6, file='imp.rcs6.RData' )
load( 'imp.rcs6.RData' )

# imp.rcs5 <- Gls( T_0 ~ rcs( time, 6 ),
#                 correlation = corAR1( form = ~time | Subject  ),
#                  data = imp,
#                  x = T )
# 
# save( imp.rcs5, file='imp.rcs5.RData' )
load( 'imp.rcs5.RData' )

imp.rcs7.aic <- AIC( imp.rcs7 )
imp.rcs6.aic <- AIC( imp.rcs6 )
imp.rcs5.aic <- AIC( imp.rcs5 )

data.frame( AIC = c(imp.rcs7.aic, imp.rcs6.aic, imp.rcs5.aic ),
            DF = c( 7, 6, 5 ) )
```

Evaluate the 6-knot RCS model. The time effects are all non-zero and the coefficients change sign indicating change in direction of the regression slope.
```{r}
print( imp.rcs6 )
anova( imp.rcs6 )
```

Below I fit a sextic polynomial model for comparison.
```{r}
# imp.pol6 <- Gls( T_0 ~ pol( time, 6 ),
#                  correlation = corAR1( form = ~time | Subject  ),
#                  data = imp,
#                  x = T )
#save( imp.pol6, file='imp.pol6.RData' )
load( 'imp.pol6.RData' )
```


Plotting the predicted values from the 6-knot RCS model and the sextic polynomial function. Again, the 7-knot RCS model is better able to capture the initial decline and then rapid rise in amplitude between the 1st and 3rd knots than the polynomial function with the same number of degrees of freedom invested in the time effect.
```{r}
imp.rcs6.pred <- data.frame( Predict( imp.rcs6, time ) )
imp.rcs6.pred$model <- '7-Knot RC Spline'
imp.pol6.pred <- data.frame( Predict( imp.pol6, time ) )
imp.pol6.pred$model <- 'Sextic Polynomial'

imp6.pred <- rbind( imp.rcs6.pred, imp.pol6.pred )
imp6.pred$model <- factor( imp6.pred$model )

impplot <- ggplot( ) +
  geom_line( data=imp, aes( x=time, y=T_0, group = Subject  ), colour='darkgray' ) +
  geom_line( data=imp6.pred, aes( time, yhat, group = model, colour = model, linetype=model ), size=1 ) +
  geom_ribbon( data=imp6.pred, aes( x=time, ymin=lower, ymax=upper, fill=model ), alpha = .3 ) +
  geom_vline( xintercept = rcspline.eval( imp$time, nk = 7, knots.only = T ), linetype = 3 ) +
  scale_color_manual( values=cbbPalette) +
  scale_fill_manual( values=cbbPalette) +
  scale_x_continuous( breaks = rcspline.eval( imp$time, nk = 7, knots.only = T ),
                      labels = c('24\nKnot 1','182\nKnot 2','342\nKnot 3','500\nKnot 4','658\nKnot 5','818\nKnot 6','976\nKnot 7')) +
  labs( y='ERP Amplitude', x='Time (ms)', colour = 'Model Type', fill = 'Model Type', linetype = 'Model Type') +
  theme( legend.position = 'bottom' )
impplot
```

## Latent Growth Curve Model: Simulated Data
Now we can apply the 

## Latent Growth Curve Model: Perceived Stress Trajectories

```{r}
load( 'cts.splines.Rdata' )
html( describe( cts.splines ) )



```

Create a wide version of the CTS data for latent growth modeling.
```{r}
cts.wide <- reshape( cts.splines,
                     direction = 'wide',
                     v.names = 'psstot',
                     timevar = 'weeks',
                     idvar = 'id',
                     sep = ''
                     )
```


We do not want to make the assumption that the time-invariant dysfunctional attitudes variable (*dasct*) affects stress trajectories in a linear manner; rather, we would like to at least allow for possible non-linearity. We'll model the effect of *dasct* with a 3-knot restricted cubic spline allowing the knots to be placed at their default values (outer knots placed at the 0.10 and 0.90 quantiles of *dasct*). There is no equivalent to the **rcs()** function provided in the *rms* package in the *lavaan* package. Consequently, we need to create $k-1$ time variables (where $k$ is the number of knots) to include in the *cts.wide* data frame in order to estimate the nonlinear effect. We use the **rcspline.eval()** function (rms package) to create new nonlinear time variable (*dasct.nonlinear*) needed to estimate a 3-knot restricted cubic spline effect of dysfunctional attitudes on stress trajectories, then creating a new data frame (*cts.wide1*) that merges this new nonlinear variable with the *cts.wide* data frame. We can then estimate the 3-knot restricted cubic spline effect by including both the *dasct* and the *dasct.nonlinear* variables as predictors in the model, representing the linear and nonlinear effects, respectively.
```{r}
das.spline <- data.frame( rcspline.eval( cts.wide$dasct, nk = 3 ) )
colnames( das.spline ) <- c( 'dasct.nonlinear' )

cts.wide1 <- cbind( cts.wide, das.spline )
head( cts.wide1 )

```


We also want to use a 3-knot restricted cubic spline to estimate a nonlinear stress trajectory. Unlike in standard regression models where time effects are captured by observed variables included in the dataset, time effects are captured by latent (unobserved) intercept & slope variables ("growth factors") in latent growth curve (LGC) models. The factor loadings are (typically) fixed at values selected to model a specific trajectory shape. To model a nonlinear trajectory using a restricted cubic spline, we need to have $k-1$ latent slope variables to capture the time effect; so we need 2 latent slope factors to estimate a 3-knot restricted cubic spline. Note, this is the same number of latent slopes needed to estimate a quadratic growth curve model. The question is: how do we constrain the factor loadings in order to estimate the appropriate restricted cubic spline trajectory. Again, the **rcspline.eval()** function can help us so that we don't have to figure it manually.  
```{r}
knots <- data.frame( rcspline.eval( cts.splines$weeks, nk = 3, knots = c( 4, 8, 14 ), inclx = T ) )
knots1 <- knots[ !duplicated( knots$x ), ] 
colnames( knots1 ) <- c('Linear Slope','Nonlinear Slope' )
knots1

```


```{r}
stress.lgc1 <- '
## Define the latent growth factors -- intercept, linear slope, and nonlinear slope
i =~ 1*psstot0 + 1*psstot2 + 1*psstot4 + 1*psstot6 + 1*psstot8 + 1*psstot10 + 1*psstot12 + 1*psstot13
lin =~ 0*psstot0 + 2*psstot2 + 4*psstot4 + 6*psstot6 + 8*psstot8 + 10*psstot10 + 12*psstot12 + 13*psstot13
nonlin =~ 0*psstot0 + 0*psstot2 + 0*psstot4 + 0.08*psstot6 + 0.64*psstot8 + 2.026667*psstot10 + 4.053333*psstot12 + 5.206667*psstot13
## Estimate first-order autoregressive effect -- hold effect constant over time by giving each the same label -- phi
# psstot13 ~ phi*psstot12
# psstot12 ~ phi*psstot10
# psstot10 ~ phi*psstot8
# psstot8 ~ phi*psstot6
# psstot6 ~ phi*psstot4
# psstot4 ~ phi*psstot2
# psstot2 ~ phi*psstot0
## Constrain variances of latent growth models to = 0 -- i.e., no random effects
i ~~ i
lin ~~ lin
nonlin ~~ nonlin
i ~~ lin
i ~~ nonlin
lin ~~ nonlin
## Constrain error variances to be constant over time
psstot0 ~~ e*psstot0
psstot2 ~~ e*psstot2
psstot4 ~~ e*psstot4
psstot6 ~~ e*psstot6
psstot8 ~~ e*psstot8
psstot10 ~~ e*psstot10
psstot12 ~~ e*psstot12
psstot13 ~~ e*psstot13
## Estimate effects of DAS on stress trajectories
i  ~ dasct + dasct.nonlinear
' 

stress.lgc1.fit <- growth( stress.lgc1,
                          data = cts.wide1,
                          estimator = 'ml' )
summary( stress.lgc1.fit, fit.measures = T )
```




```{r}
stress.lgc2 <- '
## Define the latent growth factors -- intercept, linear slope, and nonlinear slope
i =~ 1*psstot0 + 1*psstot2 + 1*psstot4 + 1*psstot6 + 1*psstot8 + 1*psstot10 + 1*psstot12 + 1*psstot13
lin =~ 0*psstot0 + 2*psstot2 + 4*psstot4 + 6*psstot6 + 8*psstot8 + 10*psstot10 + 12*psstot12 + 13*psstot13
## Estimate first-order autoregressive effect -- hold effect constant over time by giving each the same label -- phi
# psstot13 ~ phi*psstot12
# psstot12 ~ phi*psstot10
# psstot10 ~ phi*psstot8
# psstot8 ~ phi*psstot6
# psstot6 ~ phi*psstot4
# psstot4 ~ phi*psstot2
# psstot2 ~ phi*psstot0
## Constrain variances of latent growth models to = 0 -- i.e., no random effects
i ~~ i
lin ~~ lin
i ~~ lin
## Constrain error variances to be constant over time
psstot0 ~~ e*psstot0
psstot2 ~~ e*psstot2
psstot4 ~~ e*psstot4
psstot6 ~~ e*psstot6
psstot8 ~~ e*psstot8
psstot10 ~~ e*psstot10
psstot12 ~~ e*psstot12
psstot13 ~~ e*psstot13
## Estimate effects of DAS on stress trajectories
i  ~ dasct + dasct.nonlinear
' 

stress.lgc2.fit <- growth( stress.lgc2,
                          data = cts.wide1,
                          estimator = 'ml' )
summary( stress.lgc2.fit, fit.measures = T )
```




```{r}
anova( stress.lgc1.fit, stress.lgc2.fit )
```








```{r}

dd.cts <- datadist( cts.splines )
options( datadist = 'dd.cts')
gls.stress1 <- Gls( psstot ~ rcs( weeks, 3),
                    correlation = corAR1( form =~ weeks | id ),
                    data = cts.splines,
                    x = T )
summary( gls.stress1 )
print( gls.stress1 )
```


```{r}
lme.stress1 <- lme( psstot ~ rcs( weeks, 3) + rcs( dasct, 3 ),
                    random =~ rcs( weeks, 3 ) | id,
                    data = cts.splines,
                    na.action = 'na.omit',
                    method = 'ML')
summary( lme.stress1 )

```





